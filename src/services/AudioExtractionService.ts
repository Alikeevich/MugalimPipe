import { FFmpeg } from '@ffmpeg/ffmpeg';
import { fetchFile } from '@ffmpeg/util'; // <--- –ò–º–ø–æ—Ä—Ç –∏–∑ –Ω–æ–≤–æ–≥–æ –ø–∞–∫–µ—Ç–∞

export class AudioExtractionService {
  // –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∞—Å—Å–∞, –∞ –Ω–µ –≤—ã–∑—ã–≤–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é
  private static ffmpeg = new FFmpeg(); // <--- –°–æ–∑–¥–∞–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –∫–ª–∞—Å—Å–∞

  static async extractAudioFromVideo(videoFile: File): Promise<AudioBuffer> {
    console.log('üé¨ Extracting audio with ffmpeg.wasm...');

    // –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ–ø–µ—Ä—å - —ç—Ç–æ –º–µ—Ç–æ–¥ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞, –∞ –Ω–µ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π
    if (!this.ffmpeg.loaded) { // <--- –°–≤–æ–π—Å—Ç–≤–æ `loaded` –≤–º–µ—Å—Ç–æ `isLoaded()`
      await this.ffmpeg.load({
        coreURL: 'https://unpkg.com/@ffmpeg/core@0.12.6/dist/esm/ffmpeg-core.js' // <--- –Ø–≤–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ URL
      });
    }

    // –ó–∞–ø–∏—Å—å —Ñ–∞–π–ª–∞ –≤ –≤–∏—Ä—Ç—É–∞–ª—å–Ω—É—é –§–°
    await this.ffmpeg.writeFile('inputVideo', await fetchFile(videoFile)); // <--- –ú–µ—Ç–æ–¥ `writeFile` –≤–º–µ—Å—Ç–æ `FS`

    // –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ wav
    await this.ffmpeg.exec([ // <--- –ú–µ—Ç–æ–¥ `exec` –≤–º–µ—Å—Ç–æ `run`
      '-i', 'inputVideo',
      '-vn',
      '-acodec', 'pcm_s16le',
      '-ar', '16000',
      '-ac', '1',
      'audio.wav'
    ]);

    const data = await this.ffmpeg.readFile('audio.wav'); // <--- –ú–µ—Ç–æ–¥ `readFile` –≤–º–µ—Å—Ç–æ `FS`
    const blob = new Blob([data], { type: 'audio/wav' });

    // Decode to AudioBuffer to keep old API shape
    const audioContext = new AudioContext({ sampleRate: 16000 });
    const arrayBuffer = await blob.arrayBuffer();
    const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

    console.log('‚úÖ Real audio extracted');
    return audioBuffer;
  }
  static async extractAudioUsingFFmpeg(videoFile: File): Promise<Blob> {
    const audioBuffer = await this.extractAudioFromVideo(videoFile);
    return this.audioBufferToWav(audioBuffer);
  }

  static audioBufferToWav(buffer: AudioBuffer): Blob {
    const length = buffer.length;
    const numberOfChannels = buffer.numberOfChannels;
    const sampleRate = buffer.sampleRate;
    
    // Calculate buffer size with proper alignment
    const bytesPerSample = 2; // 16-bit
    const dataSize = length * numberOfChannels * bytesPerSample;
    const arrayBuffer = new ArrayBuffer(44 + dataSize);
    const view = new DataView(arrayBuffer);
    
    // Helper function to write strings
    const writeString = (offset: number, string: string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    };
    
    // Enhanced WAV header
    writeString(0, 'RIFF');
    view.setUint32(4, 36 + dataSize, true);
    writeString(8, 'WAVE');
    writeString(12, 'fmt ');
    view.setUint32(16, 16, true); // PCM format chunk size
    view.setUint16(20, 1, true); // Audio format (1 = PCM)
    view.setUint16(22, numberOfChannels, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * numberOfChannels * bytesPerSample, true); // Byte rate
    view.setUint16(32, numberOfChannels * bytesPerSample, true); // Block align
    view.setUint16(34, 16, true); // Bits per sample
    writeString(36, 'data');
    view.setUint32(40, dataSize, true);
    
    // Convert audio data with enhanced quality
    let offset = 44;
    for (let i = 0; i < length; i++) {
      for (let channel = 0; channel < numberOfChannels; channel++) {
        let sample = buffer.getChannelData(channel)[i];
        
        // Apply soft clipping to prevent distortion
        sample = Math.max(-1, Math.min(1, sample));
        
        // Convert to 16-bit integer with dithering
        const intSample = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
        const ditheredSample = Math.round(intSample + (Math.random() - 0.5));
        
        view.setInt16(offset, ditheredSample, true);
        offset += 2;
      }
    }
    
    return new Blob([arrayBuffer], { type: 'audio/wav' });
  }

  /**
   * Enhanced audio characteristics analysis with better speech detection
   */
  static analyzeAudioCharacteristics(audioBuffer: AudioBuffer) {
    const channelData = audioBuffer.getChannelData(0);
    const sampleRate = audioBuffer.sampleRate;
    const length = channelData.length;
    
    // Enhanced RMS calculation with windowing
    let rms = 0;
    const windowSize = Math.floor(sampleRate * 0.025); // 25ms windows
    const numWindows = Math.floor(length / windowSize);
    
    for (let w = 0; w < numWindows; w++) {
      let windowRms = 0;
      const start = w * windowSize;
      const end = Math.min(start + windowSize, length);
      
      for (let i = start; i < end; i++) {
        windowRms += channelData[i] * channelData[i];
      }
      
      windowRms = Math.sqrt(windowRms / (end - start));
      rms += windowRms;
    }
    
    rms = rms / numWindows;
    
    // Enhanced zero crossing rate calculation
    let zeroCrossings = 0;
    for (let i = 1; i < length; i++) {
      if ((channelData[i] >= 0) !== (channelData[i - 1] >= 0)) {
        zeroCrossings++;
      }
    }
    const zeroCrossingRate = zeroCrossings / length;
    
    // Advanced speech activity detection
    const frameSize = Math.floor(sampleRate * 0.025); // 25ms frames
    const hopSize = Math.floor(frameSize / 2); // 50% overlap
    const frames = Math.floor((length - frameSize) / hopSize) + 1;
    
    let speechFrames = 0;
    let totalEnergy = 0;
    let spectralCentroid = 0;
    
    for (let i = 0; i < frames; i++) {
      const start = i * hopSize;
      const end = Math.min(start + frameSize, length);
      
      // Calculate frame energy
      let frameEnergy = 0;
      for (let j = start; j < end; j++) {
        frameEnergy += channelData[j] * channelData[j];
      }
      frameEnergy = frameEnergy / (end - start);
      totalEnergy += frameEnergy;
      
      // Calculate spectral centroid (simplified)
      let weightedSum = 0;
      let magnitudeSum = 0;
      for (let j = start; j < end; j++) {
        const magnitude = Math.abs(channelData[j]);
        weightedSum += magnitude * (j - start);
        magnitudeSum += magnitude;
      }
      const centroid = magnitudeSum > 0 ? weightedSum / magnitudeSum : 0;
      spectralCentroid += centroid;
      
      // Enhanced speech detection using multiple features
      const energyThreshold = rms * 0.15;
      const zcr = this.calculateFrameZCR(channelData, start, end);
      const zcrThreshold = 0.35;
      const centroidThreshold = frameSize * 0.3;
      
      // Multi-feature speech detection
      if (frameEnergy > energyThreshold && 
          zcr < zcrThreshold && 
          centroid > centroidThreshold) {
        speechFrames++;
      }
    }
    
    const speechRatio = frames > 0 ? speechFrames / frames : 0;
    const averageEnergy = frames > 0 ? totalEnergy / frames : 0;
    const avgSpectralCentroid = frames > 0 ? spectralCentroid / frames : 0;
    
    // Enhanced quality score calculation
    const energyScore = Math.min(1, averageEnergy * 10);
    const speechScore = speechRatio;
    const spectralScore = Math.min(1, avgSpectralCentroid / (frameSize * 0.5));
    
    const qualityScore = (energyScore * 0.4) + (speechScore * 0.4) + (spectralScore * 0.2);
    
    return {
      duration: length / sampleRate,
      averageVolume: rms,
      zeroCrossingRate,
      speechRatio,
      estimatedSpeechTime: speechRatio * (length / sampleRate),
      averageEnergy,
      spectralCentroid: avgSpectralCentroid,
      qualityScore,
      frameCount: frames,
      speechFrameCount: speechFrames,
      energyScore,
      spectralScore
    };
  }

  /**
   * Calculate zero crossing rate for a frame
   */
  private static calculateFrameZCR(data: Float32Array, start: number, end: number): number {
    let crossings = 0;
    for (let i = start + 1; i < end; i++) {
      if ((data[i] >= 0) !== (data[i - 1] >= 0)) {
        crossings++;
      }
    }
    return crossings / (end - start - 1);
  }

  /**
   * Enhanced audio buffer validation with detailed analysis
   */
  static validateAudioBuffer(audioBuffer: AudioBuffer): {
    isValid: boolean;
    quality: 'excellent' | 'good' | 'fair' | 'poor';
    issues: string[];
    recommendations: string[];
    score: number;
  } {
    const issues: string[] = [];
    const recommendations: string[] = [];
    
    const characteristics = this.analyzeAudioCharacteristics(audioBuffer);
    
    // Enhanced validation checks
    if (characteristics.duration < 5) {
      issues.push('–ö–æ—Ä–æ—Ç–∫–æ–µ –∞—É–¥–∏–æ');
      recommendations.push('–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–∏–¥–µ–æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –Ω–µ –º–µ–Ω–µ–µ 10 —Å–µ–∫—É–Ω–¥');
    }
    
    if (characteristics.averageVolume < 0.005) {
      issues.push('–û—á–µ–Ω—å —Ç–∏—Ö–æ–µ –∞—É–¥–∏–æ');
      recommendations.push('–£–≤–µ–ª–∏—á—å—Ç–µ –≥—Ä–æ–º–∫–æ—Å—Ç—å –∑–∞–ø–∏—Å–∏ –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω');
    } else if (characteristics.averageVolume > 0.9) {
      issues.push('–ü–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∞—É–¥–∏–æ');
      recommendations.push('–£–º–µ–Ω—å—à–∏—Ç–µ –≥—Ä–æ–º–∫–æ—Å—Ç—å –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –∏—Å–∫–∞–∂–µ–Ω–∏–π');
    }
    
    if (characteristics.speechRatio < 0.2) {
      issues.push('–ú–∞–ª–æ —Ä–µ—á–µ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞');
      recommendations.push('–£–±–µ–¥–∏—Ç–µ—Å—å –≤ –Ω–∞–ª–∏—á–∏–∏ –∞–∫—Ç–∏–≤–Ω–æ–π —Ä–µ—á–∏ –≤ –≤–∏–¥–µ–æ');
    }
    
    if (characteristics.zeroCrossingRate > 0.5) {
      issues.push('–í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å —à—É–º–∞');
      recommendations.push('–£–ª—É—á—à–∏—Ç–µ —É—Å–ª–æ–≤–∏—è –∑–∞–ø–∏—Å–∏ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ');
    }
    
    // Enhanced quality determination
    const qualityScore = characteristics.qualityScore;
    let quality: 'excellent' | 'good' | 'fair' | 'poor';
    
    if (qualityScore > 0.8) quality = 'excellent';
    else if (qualityScore > 0.6) quality = 'good';
    else if (qualityScore > 0.4) quality = 'fair';
    else quality = 'poor';
    
    // Calculate overall score (0-100)
    const score = Math.round(qualityScore * 100);
    
    return {
      isValid: issues.length === 0 && qualityScore > 0.3,
      quality,
      issues,
      recommendations,
      score
    };
  }
}